{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad5a073f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\nateisgreat98/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a1a957a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = Image.open(r'C:\\Users\\nateisgreat98\\Google Drive\\Classes\\Machine Learning\\RT\\HW0\\Alaskan_Malamute_Puppy.jpg')\n",
    "img2 = Image.open(r'C:\\Users\\nateisgreat98\\Google Drive\\Classes\\Machine Learning\\RT\\HW0\\Firetruck.jpg')\n",
    "img3 = Image.open(r'C:\\Users\\nateisgreat98\\Google Drive\\Classes\\Machine Learning\\RT\\HW0\\House.jpg')\n",
    "img4 = Image.open(r'C:\\Users\\nateisgreat98\\Google Drive\\Classes\\Machine Learning\\RT\\HW0\\Parakeet.jpg')\n",
    "img5 = Image.open(r'C:\\Users\\nateisgreat98\\Google Drive\\Classes\\Machine Learning\\RT\\HW0\\R.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8882a8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "transforms.Resize(256),\n",
    "transforms.CenterCrop(224),\n",
    "transforms.ToTensor(),\n",
    "transforms.Normalize(\n",
    "mean=[0.485, 0.456, 0.406],\n",
    "std=[0.229, 0.224, 0.225]\n",
    ")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8115c809",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t1 = preprocess(img1)\n",
    "img_t2 = preprocess(img2)\n",
    "img_t3 = preprocess(img3)\n",
    "img_t4 = preprocess(img4)\n",
    "img_t5 = preprocess(img5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae9b97a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_1t = torch.unsqueeze(img_t1, 0)\n",
    "batch_2t = torch.unsqueeze(img_t2, 0)\n",
    "batch_3t = torch.unsqueeze(img_t3, 0)\n",
    "batch_4t = torch.unsqueeze(img_t4, 0)\n",
    "batch_5t = torch.unsqueeze(img_t5, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3dd382ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-7.2528e-01, -2.6657e+00, -9.8198e-01, -2.6134e+00, -4.9096e+00,\n",
      "        -9.2505e-01, -1.7393e+00, -3.6025e+00,  1.1346e+00, -1.0801e+00,\n",
      "         1.4629e+00,  3.9468e-01, -2.3595e+00,  1.0618e+00, -4.5049e+00,\n",
      "         5.5750e-01,  2.4262e+00, -3.3463e-01, -4.4585e-01, -1.7378e+00,\n",
      "         2.4120e+00,  1.8367e-01,  2.5369e+00,  4.8081e-01, -4.4507e-01,\n",
      "        -1.0498e+00,  1.0160e-01,  3.4054e-01, -3.8267e-01, -2.3751e+00,\n",
      "         7.1556e-01, -1.9797e+00, -7.7927e-01, -1.5930e+00, -5.1454e-01,\n",
      "         1.9124e+00,  2.5380e+00, -1.8379e+00,  5.9102e-01,  1.9476e+00,\n",
      "        -9.7445e-01, -9.5686e-01, -1.7799e+00, -6.7765e-01,  5.1507e-01,\n",
      "        -2.4702e+00, -4.8908e-01,  6.2474e-01, -2.6842e+00,  8.5719e-01,\n",
      "         7.8543e-01, -1.7946e-03,  1.4822e+00,  1.5410e+00,  9.7253e-01,\n",
      "         2.0888e+00,  5.3488e-01,  2.9090e+00,  3.5188e+00,  1.9141e+00,\n",
      "         2.2318e+00, -7.8881e-01,  1.9041e+00, -1.5851e+00,  1.5128e+00,\n",
      "        -2.8262e-01,  1.2858e+00,  1.3199e+00,  1.9482e+00, -6.3466e+00,\n",
      "         1.0626e+00, -2.2617e+00,  1.1820e-01,  6.6155e-01, -9.8011e-01,\n",
      "        -2.0268e+00, -7.3715e-01,  6.7886e-02,  2.1663e-01, -5.4170e-01,\n",
      "         4.6403e-01,  3.4249e-01,  1.2488e+00,  9.1384e-01, -1.0830e+00,\n",
      "        -2.3925e+00,  1.5236e+00, -8.0209e-01, -3.0649e+00, -3.5896e+00,\n",
      "        -1.8480e+00, -1.8420e+00, -1.8059e+00,  1.4477e+00,  7.7077e-01,\n",
      "        -1.1851e-01, -2.2253e+00,  1.8164e+00,  2.2404e+00,  1.3687e+00,\n",
      "         1.8936e-01, -5.0700e+00, -1.3543e+00, -1.0400e+00, -2.2527e+00,\n",
      "        -7.2499e-01, -3.8999e-01, -4.5872e+00, -3.0016e+00, -4.0126e+00,\n",
      "        -4.1935e+00, -3.8056e+00, -9.0482e-01,  1.2145e+00, -3.5691e-02,\n",
      "        -3.2852e+00,  2.9180e-01, -8.5092e-01,  1.0338e+00,  7.8870e-01,\n",
      "         1.7435e+00,  8.8470e-01,  8.2642e-01, -1.1768e-01,  2.8384e+00,\n",
      "         8.2692e-01, -2.9354e+00, -1.1875e-01,  5.8625e-02, -1.6104e+00,\n",
      "        -3.6336e+00, -2.3854e-02, -3.0513e-01,  8.3902e-01, -3.3569e-01,\n",
      "         2.9021e+00,  2.3654e+00,  1.3813e+00,  1.0060e+00,  6.7382e+00,\n",
      "         4.0431e+00,  6.2377e+00,  2.8214e+00,  2.8234e+00, -2.7299e+00,\n",
      "        -3.0722e+00,  3.3327e+00, -4.0308e+00, -4.5633e+00, -5.3470e+00,\n",
      "        -4.8800e+00,  4.6985e+00,  4.3230e+00,  3.8106e+00,  4.2598e+00,\n",
      "         5.2382e+00,  2.2377e+00,  5.0725e+00,  9.4759e-01, -1.9313e+00,\n",
      "         2.3939e+00,  4.0303e-01,  4.2577e+00, -1.9703e+00, -7.3465e-01,\n",
      "        -2.3576e+00, -5.0772e-01,  7.7173e-01, -1.9877e+00,  6.1206e+00,\n",
      "         2.3111e+00,  4.3326e-01,  2.8749e+00, -6.2925e-01,  4.4737e+00,\n",
      "         3.9892e+00,  5.3279e+00,  2.4230e+00, -1.1427e+00,  1.6096e+00,\n",
      "         1.6376e+00,  1.0224e+00,  4.9459e-01, -7.8776e-01,  6.0804e-01,\n",
      "         2.4260e+00,  4.6900e+00,  2.5865e+00,  4.8103e+00,  8.1222e-01,\n",
      "         1.5292e+00, -5.5641e-01,  6.5591e-01,  4.0341e+00,  5.2206e+00,\n",
      "         1.1667e+00,  5.8261e+00,  2.1110e+00,  4.0747e+00,  5.1427e-01,\n",
      "         6.7452e+00,  2.2357e+00,  1.3255e+00,  1.8309e+00,  5.7222e+00,\n",
      "         1.5273e+00, -2.4358e-02,  2.1806e+00, -1.3407e-01,  9.2283e-01,\n",
      "        -1.6463e+00, -1.3292e+00,  1.8912e+00, -2.8688e-01, -7.8401e-01,\n",
      "         1.3192e+00,  1.5831e+00,  1.8737e+00,  2.2998e+00,  1.2598e+00,\n",
      "         2.9561e+00,  6.8330e-01,  3.1951e+00,  2.2286e+00,  3.9577e+00,\n",
      "        -1.6546e+00,  1.4884e+00,  3.5309e+00, -2.8216e+00,  6.7604e+00,\n",
      "         8.5020e+00,  1.0574e+01,  9.7659e+00,  2.5113e+00,  9.3413e-01,\n",
      "         3.2077e+00, -1.7984e+00, -2.6459e+00,  2.3918e+00,  5.3154e+00,\n",
      "         5.2115e+00,  4.6811e+00, -2.7670e+00, -2.4723e+00,  6.5345e+00,\n",
      "        -1.7452e+00, -2.0155e+00,  2.9819e+00,  1.4176e+01,  1.6317e+01,\n",
      "         1.4541e+01,  2.8661e+00,  8.3854e-01,  1.2587e+00, -4.9834e-02,\n",
      "         3.2742e+00,  4.4331e+00,  7.3377e+00,  4.6376e+00,  5.1624e+00,\n",
      "         1.2981e+00,  7.2312e+00,  1.0616e+00,  8.1886e+00,  8.1771e+00,\n",
      "         2.2535e+00,  1.7912e+00,  1.5003e+00, -2.6555e+00,  8.9126e+00,\n",
      "         4.6807e+00,  5.8590e+00,  5.2451e+00,  3.9537e+00,  2.6084e+00,\n",
      "         4.7369e+00, -3.2173e-01,  4.9093e+00,  5.8546e+00,  9.1261e+00,\n",
      "         4.3544e+00,  5.5593e+00,  4.1171e+00,  5.0353e+00,  2.4901e-01,\n",
      "         4.2512e+00, -2.0193e-02,  2.7441e+00, -4.4134e-01,  1.8889e+00,\n",
      "        -2.5063e+00, -3.3995e-01,  2.3868e+00,  1.2884e+00, -3.5242e+00,\n",
      "        -2.9983e+00, -4.4462e+00,  1.1131e+00, -1.2253e+00, -1.0157e+00,\n",
      "         1.3173e+00, -8.4705e-01, -7.1665e-01, -1.4007e+00, -3.2585e+00,\n",
      "        -3.6946e+00, -5.3090e-01, -1.3428e+00, -1.9341e+00,  8.5685e-01,\n",
      "         1.1151e+00,  1.6766e-01,  2.4658e+00,  1.6855e-02, -1.8456e+00,\n",
      "         2.3648e-01, -3.6584e+00, -6.2240e-01, -6.6823e-01, -2.5597e+00,\n",
      "        -1.6319e+00, -1.6942e+00,  1.7127e+00, -1.3566e-01,  3.0587e+00,\n",
      "         4.1698e+00,  2.0887e-01, -2.0909e+00, -1.3483e+00, -3.0058e+00,\n",
      "        -4.8820e-01,  8.7462e-01,  1.0141e+00,  3.3776e+00, -2.8220e+00,\n",
      "         1.1656e+00, -2.9463e+00, -2.5531e+00,  2.3238e+00, -5.7680e+00,\n",
      "        -8.7252e-01, -5.4106e-01, -7.3711e-01, -2.1738e+00, -3.5581e+00,\n",
      "        -5.8809e-01, -7.8684e-01, -4.7227e+00,  3.4917e-02, -1.3862e+00,\n",
      "        -3.6892e+00, -6.0481e+00,  1.0324e-01, -1.1829e-01, -5.8236e+00,\n",
      "        -1.7327e+00,  5.8643e+00,  2.5117e+00,  5.5446e+00,  4.6134e+00,\n",
      "        -2.2371e-01,  2.1075e+00,  3.7461e+00, -3.4818e+00,  1.3941e-01,\n",
      "        -1.1973e+00, -3.5114e-01, -1.4610e+00, -1.1268e+00, -1.8777e+00,\n",
      "         2.0303e+00,  9.4791e-01, -4.8920e-01,  2.0663e+00, -8.8831e-02,\n",
      "        -2.8642e-01, -2.4719e+00,  1.8299e+00,  1.5869e+00, -7.3199e-04,\n",
      "         2.7032e+00, -1.9091e+00,  3.3338e+00,  5.6403e+00,  2.9962e+00,\n",
      "        -3.8548e+00, -4.3044e+00,  1.3254e+00, -5.1635e-01,  9.7828e-01,\n",
      "        -1.6330e+00,  9.7614e-01, -3.6886e+00, -6.1983e+00, -8.4573e-01,\n",
      "         1.4609e+00, -5.3845e+00, -3.1764e+00, -1.8945e+00, -4.4431e+00,\n",
      "        -2.4477e+00,  9.5351e-01, -2.4451e+00, -3.8677e+00, -5.9599e+00,\n",
      "        -2.5930e+00, -4.8155e-01, -5.1054e+00,  5.3381e-01,  4.5097e+00,\n",
      "        -1.2564e+00,  9.7796e-01,  5.0354e-01, -3.4881e+00,  5.1925e-01,\n",
      "        -2.0440e+00, -1.7149e+00, -4.7003e-01, -1.8898e+00, -1.9424e+00,\n",
      "        -3.4154e-01, -1.2177e+00,  2.8698e+00, -3.0124e+00, -3.7394e+00,\n",
      "        -8.4897e-01,  4.8351e+00,  7.5828e-01,  5.6895e+00, -1.7562e+00,\n",
      "        -4.8984e-01, -5.2513e-01,  1.7648e+00, -2.6163e+00, -3.3616e+00,\n",
      "         3.0194e+00, -8.6160e-01,  1.9606e+00,  1.0605e+00, -8.6794e-01,\n",
      "         3.9034e-01, -7.8748e-02,  2.0938e+00, -3.0882e+00,  6.7664e-01,\n",
      "        -1.2082e+00, -1.8716e+00, -4.2760e-01, -7.1637e-01, -7.3058e-01,\n",
      "        -1.4959e+00,  4.0699e-01, -2.6614e+00,  1.8066e+00,  2.4150e+00,\n",
      "         2.2986e+00, -5.1545e-01,  2.4643e+00, -2.0989e+00,  1.6639e+00,\n",
      "         6.8729e-01,  1.1585e+00, -1.1130e+00,  2.9176e+00, -1.3499e+00,\n",
      "        -3.5235e+00, -2.7316e+00, -6.1382e+00, -3.7468e+00,  4.7403e+00,\n",
      "         2.5474e+00, -1.0906e+00,  1.7097e+00, -2.8398e-01, -3.4394e+00,\n",
      "        -2.1816e+00,  1.7172e-01,  3.0786e-01,  2.2785e-03,  4.5859e+00,\n",
      "        -3.6806e+00, -1.2390e+00, -4.7266e-01,  2.1998e+00, -3.8859e-01,\n",
      "        -1.1890e-01, -4.8393e-01,  7.5744e-01,  2.0577e+00,  9.8556e-02,\n",
      "         4.7816e-01, -1.3442e+00, -6.1449e-01, -7.4687e-01,  9.3457e-01,\n",
      "        -3.8018e-01, -5.1178e-01,  3.8006e-01,  2.4500e-02, -1.8831e+00,\n",
      "        -6.9291e+00, -1.5803e+00, -2.1913e-01,  7.9731e-01,  5.5718e-01,\n",
      "        -9.9030e-01, -9.7538e-01, -8.0352e-01,  1.3344e+00, -1.3302e+00,\n",
      "        -2.7263e+00, -2.6370e-01,  2.2993e+00,  9.1346e-01, -2.5723e+00,\n",
      "        -1.0089e+00, -1.0384e-01, -1.7415e+00,  1.3615e+00, -1.6419e-01,\n",
      "        -2.2815e+00,  1.4224e+00,  2.6892e+00, -4.7799e-01, -3.0775e-01,\n",
      "         3.2827e-01, -1.3497e-01, -1.8512e+00,  4.2837e-01, -1.7925e+00,\n",
      "         3.4780e-02, -1.9145e+00, -6.0079e-01, -1.2566e+00,  2.5091e+00,\n",
      "         2.2749e+00, -3.1348e-01,  7.3682e+00,  7.8457e-01,  1.1096e+00,\n",
      "        -2.2083e+00,  1.3012e+00,  3.2497e+00,  2.2418e+00,  2.0965e+00,\n",
      "         3.2092e-01, -2.9273e+00, -5.6017e-03, -6.3866e-01, -2.8107e+00,\n",
      "        -3.9623e-01, -1.3362e+00,  1.8605e+00,  1.0808e+00, -1.0072e+00,\n",
      "        -3.7754e+00, -2.0620e+00, -8.2991e-01,  1.7383e+00,  1.6992e+00,\n",
      "        -2.7739e+00, -1.1120e+00, -1.5384e+00, -3.4576e-01, -2.6154e+00,\n",
      "        -4.1430e-01,  3.2388e+00,  2.8189e+00, -1.0200e+00, -1.8697e+00,\n",
      "        -2.1428e+00, -9.5739e-01,  1.2413e+00, -1.6403e+00,  3.6983e+00,\n",
      "        -2.1542e-01, -3.8475e+00,  3.7817e+00,  7.5458e-01, -1.0308e-01,\n",
      "         2.6197e-01, -5.0668e-01, -8.6147e-01, -1.1025e+00, -3.9105e-01,\n",
      "         2.7215e-01, -5.0790e-01,  1.1484e-01,  7.8983e-01, -4.9559e-01,\n",
      "         3.4113e-01, -1.7395e+00,  5.5778e-01,  1.3568e+00,  7.5424e-01,\n",
      "        -1.3026e+00, -6.9684e-01, -2.3253e+00, -2.2837e+00,  1.1803e+00,\n",
      "        -1.0773e+00, -1.7590e+00, -4.7434e-01, -9.4614e-01,  4.8540e-01,\n",
      "        -3.6679e-01, -1.9976e+00,  1.1054e+00, -1.7810e+00, -7.7549e-02,\n",
      "        -1.0528e+00,  2.6177e+00, -1.7033e+00, -3.2696e+00, -1.3031e+00,\n",
      "        -1.3850e+00, -1.2169e+00, -1.6543e+00,  1.0152e+00, -6.3386e-02,\n",
      "         1.6443e+00,  2.2926e+00, -6.0352e-01, -2.3961e+00,  4.0112e+00,\n",
      "         1.2768e+00, -1.4909e+00, -2.2325e+00, -3.3611e+00, -8.3960e-01,\n",
      "        -3.1324e+00,  1.8290e-01,  4.4117e-01, -1.0316e-01, -1.4439e+00,\n",
      "         2.6134e+00, -4.3270e-02, -5.4641e-01, -7.1993e-01, -1.4831e+00,\n",
      "        -8.8482e-01,  2.5062e-01, -1.8582e-01,  1.9226e+00, -2.5426e+00,\n",
      "        -1.6691e+00,  1.6714e+00,  1.1467e+00, -3.6880e+00, -3.1145e+00,\n",
      "        -1.6243e-03, -1.2975e+00, -1.5432e+00,  2.7403e+00, -2.3889e+00,\n",
      "        -4.0766e-01, -1.6845e+00, -1.2971e+00, -1.6122e+00,  6.5672e-01,\n",
      "         8.5772e-01,  1.6187e-01, -2.8387e+00, -1.4752e+00,  1.3107e+00,\n",
      "         8.1119e-01, -6.9928e-01, -2.0630e+00, -1.9878e+00, -3.1562e+00,\n",
      "        -1.2627e-01,  2.8050e+00,  3.3845e-01,  6.1761e-01, -8.2913e-01,\n",
      "        -3.4970e+00,  7.0773e-01, -1.8590e+00, -1.2943e+00, -2.7958e-01,\n",
      "        -1.2639e+00,  8.3391e-01, -3.2904e+00,  2.3476e+00,  1.5560e+00,\n",
      "        -3.8183e-01, -9.0628e-01,  3.6570e-01, -1.0183e+00, -1.0552e-01,\n",
      "        -1.9843e+00,  3.6349e-01,  4.4716e-01,  1.1372e+00, -2.0326e+00,\n",
      "        -3.2381e+00, -1.5792e+00, -1.4488e+00,  8.5492e-01,  1.1651e+00,\n",
      "         1.3776e+00, -1.3057e+00, -2.4759e+00, -1.7295e+00, -4.5046e-01,\n",
      "        -1.1732e+00, -1.8271e+00, -1.8672e+00, -1.5575e-01, -3.2254e+00,\n",
      "        -2.5759e+00, -1.7524e-01, -2.8200e+00, -1.6796e-01, -1.0667e+00,\n",
      "        -1.8092e+00,  1.0579e+00, -2.1432e+00, -1.6240e+00, -1.2488e+00,\n",
      "        -1.0896e+00, -5.6791e-01,  5.3809e+00,  2.2624e+00, -3.4112e-01,\n",
      "         6.2438e-01, -7.3125e+00,  1.6961e-01,  1.2673e+00, -3.5984e+00,\n",
      "         8.6080e-01,  1.6731e+00, -5.5303e+00,  1.9551e+00, -5.8096e+00,\n",
      "        -1.9263e+00, -1.9442e+00, -1.5235e+00, -4.0849e-01, -3.4818e+00,\n",
      "        -3.2937e-01, -1.8636e+00,  2.1692e+00, -3.2179e+00,  1.0646e+00,\n",
      "        -3.1393e+00,  4.0888e-01, -2.8536e+00,  5.6063e-01,  5.8255e-01,\n",
      "         1.5230e+00,  7.9435e-01, -1.4829e+00,  2.1927e-01, -4.4103e-01,\n",
      "         7.9633e-01,  9.2671e-01, -1.6664e+00,  2.7209e+00, -1.7926e+00,\n",
      "        -9.2870e-01,  8.8132e-01, -6.2521e-01, -4.4012e+00, -3.0336e+00,\n",
      "        -1.5473e+00, -3.9961e-01, -1.6080e+00,  1.6620e+00,  8.4002e-01,\n",
      "        -7.3715e-01, -1.5463e+00,  8.3123e-01, -2.2771e+00, -4.5542e+00,\n",
      "         1.5237e-01,  7.2290e-01, -6.1597e-01, -2.8915e-01, -4.1749e+00,\n",
      "        -6.2037e-01, -2.6864e+00,  3.5172e-01, -1.7809e-01,  1.2292e+00,\n",
      "        -2.6568e+00, -3.5390e+00,  2.5571e+00, -2.4420e+00, -5.9043e-01,\n",
      "        -2.7001e+00, -2.8263e+00,  1.3566e+00, -3.1745e-01, -3.1769e-01,\n",
      "        -9.5705e-01, -1.6351e+00,  1.6023e+00, -3.3080e+00, -8.2988e-01,\n",
      "        -2.5393e-01, -5.5042e+00, -7.4697e-01, -2.1749e+00, -5.1563e-01,\n",
      "         6.1287e+00, -1.8433e+00,  4.8480e+00,  1.5878e+00,  2.4483e+00,\n",
      "         5.5039e-01, -4.1118e-01, -3.0116e+00,  9.9962e-01, -6.8030e-01,\n",
      "        -1.7113e+00, -2.0627e+00,  1.3523e+00,  1.6986e+00, -4.9643e-01,\n",
      "         5.5563e-01, -3.2729e+00,  3.2285e+00,  2.0856e+00, -3.6647e-01,\n",
      "        -1.5389e+00,  3.2521e+00,  1.5570e+00, -1.0802e+00, -3.0701e-01,\n",
      "        -1.7493e+00,  1.2384e+00, -4.7292e+00, -6.8747e-01, -6.6058e-01,\n",
      "         7.2112e-01, -9.0903e-01, -1.0191e+00, -5.2212e-01, -4.2876e+00,\n",
      "        -1.5362e+00, -2.0956e+00,  9.1666e-01, -1.6316e+00, -7.6067e-01,\n",
      "         1.2537e+00, -1.9107e+00, -2.1812e+00,  1.4547e-01, -9.5058e-01,\n",
      "        -1.3916e+00,  1.9397e+00,  4.5071e+00, -9.8871e-01,  2.6861e-01,\n",
      "         9.5878e-01, -1.0787e+00, -2.5465e+00,  1.7730e+00, -3.7850e+00,\n",
      "        -7.1104e-02,  6.7165e-01, -4.3895e-01, -2.4606e+00, -3.1614e+00,\n",
      "        -1.3335e+00,  6.0082e-01, -3.5445e+00, -7.6123e-01, -1.6201e+00,\n",
      "         2.5070e+00, -1.9483e+00,  2.0639e+00, -2.1822e+00, -4.2134e+00,\n",
      "         2.9209e+00,  2.8889e+00, -2.4361e+00, -7.2045e-01,  4.0179e-01,\n",
      "         7.6030e-01, -2.5073e-01, -1.9166e-01, -8.0239e-01, -6.2836e-01,\n",
      "        -1.3427e+00, -1.4915e+00, -1.1265e-01, -2.8922e+00, -1.4429e+00,\n",
      "        -1.6256e+00, -2.8796e+00,  4.1464e+00, -2.3004e-01, -3.1930e-02,\n",
      "        -1.3853e+00,  2.5856e+00, -6.6581e-01,  1.4449e+00,  1.9937e-02,\n",
      "        -1.0437e+00, -2.8947e+00, -3.0921e-01, -3.0411e-01, -5.0130e-01,\n",
      "         3.6304e-01, -3.7917e-01, -7.1995e-01, -3.0008e+00,  2.9104e+00,\n",
      "         4.0344e-01,  2.5489e-01, -1.9391e+00, -8.0769e-01, -1.0546e+00,\n",
      "        -1.3616e+00,  2.1025e+00,  1.4443e+00, -8.2381e-02, -2.8192e+00,\n",
      "        -5.2079e+00,  1.3058e+00, -3.7860e+00,  5.2448e-01, -2.2008e+00,\n",
      "         2.0564e+00,  2.4249e+00,  1.4665e-01, -3.4093e+00,  1.8053e+00,\n",
      "        -4.4405e+00, -4.0811e-01, -2.9419e+00, -3.9718e+00, -2.6878e+00,\n",
      "        -2.4630e-01,  2.1020e+00,  1.3968e+00,  1.5830e-01,  1.4263e+00,\n",
      "        -2.3238e-01,  1.9618e-01,  1.3184e+00,  2.0389e+00,  4.0610e-02,\n",
      "        -8.9575e-01,  3.9576e-01,  1.7898e+00, -2.1834e-01, -1.0311e+00,\n",
      "         1.0317e+00,  2.5862e+00, -3.1986e+00,  1.8644e+00, -6.1390e-01,\n",
      "        -2.4049e+00,  2.6536e+00, -4.7578e-01,  1.4759e+00, -1.9987e+00,\n",
      "        -5.0168e+00, -2.4488e+00, -1.4847e+00,  5.6336e-02, -2.3221e+00,\n",
      "        -4.4738e+00, -3.0496e-01, -3.4480e+00,  1.4769e+00,  6.1073e-01,\n",
      "         1.5221e+00, -2.8109e-01,  2.3845e-01, -1.9081e+00, -1.2949e+00,\n",
      "         2.4761e+00, -2.1891e-01,  1.6312e+00,  1.1955e+00, -3.9153e-01,\n",
      "        -1.4744e+00, -5.7927e+00,  1.6979e-01, -2.8470e+00, -3.0756e-01,\n",
      "         4.9787e-01,  6.6979e-01,  3.8683e+00, -5.6049e-01,  5.4806e-01,\n",
      "        -1.1566e-01, -4.1346e-01,  2.1969e+00, -1.6139e+00, -4.3257e-01,\n",
      "         3.0866e+00,  1.9751e+00,  3.2412e-01,  2.8183e+00,  2.6180e-02],\n",
      "       device='cuda:0')\n",
      "tensor([3.0638e-08, 4.4010e-09, 2.3701e-08, 4.6372e-09, 4.6667e-10, 2.5090e-08,\n",
      "        1.1115e-08, 1.7245e-09, 1.9679e-07, 2.1486e-08, 2.7326e-07, 9.3896e-08,\n",
      "        5.9773e-09, 1.8296e-07, 6.9947e-10, 1.1050e-07, 7.1605e-07, 4.5281e-08,\n",
      "        4.0515e-08, 1.1131e-08, 7.0591e-07, 7.6034e-08, 7.9984e-07, 1.0234e-07,\n",
      "        4.0546e-08, 2.2146e-08, 7.0043e-08, 8.8948e-08, 4.3157e-08, 5.8853e-09,\n",
      "        1.2942e-07, 8.7390e-09, 2.9028e-08, 1.2864e-08, 3.7825e-08, 4.2835e-07,\n",
      "        8.0070e-07, 1.0071e-08, 1.1427e-07, 4.4368e-07, 2.3880e-08, 2.4304e-08,\n",
      "        1.0672e-08, 3.2132e-08, 1.0591e-07, 5.3513e-09, 3.8800e-08, 1.1818e-07,\n",
      "        4.3200e-09, 1.4911e-07, 1.3879e-07, 6.3163e-08, 2.7857e-07, 2.9546e-07,\n",
      "        1.6734e-07, 5.1097e-07, 1.0803e-07, 1.1603e-06, 2.1353e-06, 4.2906e-07,\n",
      "        5.8955e-07, 2.8752e-08, 4.2479e-07, 1.2967e-08, 2.8725e-07, 4.7698e-08,\n",
      "        2.2890e-07, 2.3684e-07, 4.4397e-07, 1.1090e-10, 1.8311e-07, 6.5916e-09,\n",
      "        7.1216e-08, 1.2262e-07, 2.3746e-08, 8.3373e-09, 3.0276e-08, 6.7721e-08,\n",
      "        7.8581e-08, 3.6811e-08, 1.0064e-07, 8.9122e-08, 2.2058e-07, 1.5780e-07,\n",
      "        2.1424e-08, 5.7834e-09, 2.9035e-07, 2.8373e-08, 2.9522e-09, 1.7469e-09,\n",
      "        9.9693e-09, 1.0030e-08, 1.0398e-08, 2.6913e-07, 1.3677e-07, 5.6205e-08,\n",
      "        6.8364e-09, 3.8914e-07, 5.9462e-07, 2.4870e-07, 7.6468e-08, 3.9753e-10,\n",
      "        1.6334e-08, 2.2365e-08, 6.6511e-09, 3.0647e-08, 4.2842e-08, 6.4425e-10,\n",
      "        3.1452e-09, 1.1445e-09, 9.5501e-10, 1.4077e-09, 2.5603e-08, 2.1316e-07,\n",
      "        6.1058e-08, 2.3685e-09, 8.4717e-08, 2.7020e-08, 1.7792e-07, 1.3924e-07,\n",
      "        3.6176e-07, 1.5327e-07, 1.4459e-07, 5.6251e-08, 1.0813e-06, 1.4467e-07,\n",
      "        3.3604e-09, 5.6191e-08, 6.7097e-08, 1.2643e-08, 1.6718e-09, 6.1785e-08,\n",
      "        4.6636e-08, 1.4643e-07, 4.5233e-08, 1.1524e-06, 6.7380e-07, 2.5183e-07,\n",
      "        1.7305e-07, 5.3410e-05, 3.6068e-06, 3.2378e-05, 1.0631e-06, 1.0652e-06,\n",
      "        4.1273e-09, 2.9309e-09, 1.7725e-06, 1.1238e-09, 6.5979e-10, 3.0135e-10,\n",
      "        4.8071e-10, 6.9469e-06, 4.7720e-06, 2.8587e-06, 4.4796e-06, 1.1917e-05,\n",
      "        5.9304e-07, 1.0097e-05, 1.6322e-07, 9.1726e-09, 6.9329e-07, 9.4684e-08,\n",
      "        4.4703e-06, 8.8219e-09, 3.0352e-08, 5.9889e-09, 3.8084e-08, 1.3690e-07,\n",
      "        8.6699e-09, 2.8800e-05, 6.3816e-07, 9.7589e-08, 1.1215e-06, 3.3726e-08,\n",
      "        5.5484e-06, 3.4176e-06, 1.3035e-05, 7.1370e-07, 2.0183e-08, 3.1642e-07,\n",
      "        3.2542e-07, 1.7591e-07, 1.0376e-07, 2.8782e-08, 1.1623e-07, 7.1586e-07,\n",
      "        6.8881e-06, 8.4052e-07, 7.7681e-06, 1.4256e-07, 2.9200e-07, 3.6274e-08,\n",
      "        1.2193e-07, 3.5747e-06, 1.1708e-05, 2.0320e-07, 2.1452e-05, 5.2247e-07,\n",
      "        3.7226e-06, 1.0582e-07, 5.3782e-05, 5.9185e-07, 2.3818e-07, 3.9483e-07,\n",
      "        1.9337e-05, 2.9145e-07, 6.1754e-08, 5.6010e-07, 5.5337e-08, 1.5923e-07,\n",
      "        1.2197e-08, 1.6748e-08, 4.1934e-07, 4.7495e-08, 2.8890e-08, 2.3668e-07,\n",
      "        3.0815e-07, 4.1208e-07, 6.3102e-07, 2.2303e-07, 1.2164e-06, 1.2531e-07,\n",
      "        1.5447e-06, 5.8765e-07, 3.3118e-06, 1.2097e-08, 2.8032e-07, 2.1613e-06,\n",
      "        3.7656e-09, 5.4605e-05, 3.1161e-04, 2.4742e-03, 1.1028e-03, 7.7966e-07,\n",
      "        1.6104e-07, 1.5644e-06, 1.0477e-08, 4.4890e-09, 6.9183e-07, 1.2873e-05,\n",
      "        1.1603e-05, 6.8266e-06, 3.9771e-09, 5.3399e-09, 4.3566e-05, 1.1048e-08,\n",
      "        8.4321e-09, 1.2481e-06, 9.0700e-02, 7.7198e-01, 1.3071e-01, 1.1117e-06,\n",
      "        1.4636e-07, 2.2278e-07, 6.0200e-08, 1.6719e-06, 5.3272e-06, 9.7267e-05,\n",
      "        6.5364e-06, 1.1047e-05, 2.3175e-07, 8.7440e-05, 1.8293e-07, 2.2777e-04,\n",
      "        2.2516e-04, 6.0245e-07, 3.7943e-07, 2.8366e-07, 4.4459e-09, 4.6983e-04,\n",
      "        6.8239e-06, 2.2171e-05, 1.1999e-05, 3.2984e-06, 8.5910e-07, 7.2186e-06,\n",
      "        4.5869e-08, 8.5770e-06, 2.2073e-05, 5.8167e-04, 4.9243e-06, 1.6430e-05,\n",
      "        3.8838e-06, 9.7286e-06, 8.1168e-08, 4.4415e-06, 6.2011e-08, 9.8397e-07,\n",
      "        4.0698e-08, 4.1841e-07, 5.1613e-09, 4.5040e-08, 6.8836e-07, 2.2950e-07,\n",
      "        1.8651e-09, 3.1557e-09, 7.4176e-10, 1.9260e-07, 1.8582e-08, 2.2915e-08,\n",
      "        2.3623e-07, 2.7125e-08, 3.0903e-08, 1.5592e-08, 2.4327e-09, 1.5729e-09,\n",
      "        3.7211e-08, 1.6522e-08, 9.1467e-09, 1.4906e-07, 1.9298e-07, 7.4827e-08,\n",
      "        7.4497e-07, 6.4352e-08, 9.9938e-09, 8.0158e-08, 1.6308e-09, 3.3958e-08,\n",
      "        3.2436e-08, 4.8930e-09, 1.2374e-08, 1.1627e-08, 3.5081e-07, 5.5249e-08,\n",
      "        1.3478e-06, 4.0943e-06, 7.7974e-08, 7.8192e-09, 1.6431e-08, 3.1323e-09,\n",
      "        3.8835e-08, 1.5173e-07, 1.7445e-07, 1.8541e-06, 3.7642e-09, 2.0299e-07,\n",
      "        3.3241e-09, 4.9255e-09, 6.4633e-07, 1.9779e-10, 2.6443e-08, 3.6835e-08,\n",
      "        3.0277e-08, 7.1971e-09, 1.8030e-09, 3.5143e-08, 2.8809e-08, 5.6261e-10,\n",
      "        6.5525e-08, 1.5821e-08, 1.5814e-09, 1.4948e-10, 7.0158e-08, 5.6217e-08,\n",
      "        1.8711e-10, 1.1187e-08, 2.2287e-05, 7.7996e-07, 1.6189e-05, 6.3801e-06,\n",
      "        5.0593e-08, 5.2062e-07, 2.6801e-06, 1.9458e-09, 7.2742e-08, 1.9109e-08,\n",
      "        4.4539e-08, 1.4681e-08, 2.0505e-08, 9.6774e-09, 4.8195e-07, 1.6327e-07,\n",
      "        3.8796e-08, 4.9960e-07, 5.7898e-08, 4.7517e-08, 5.3422e-09, 3.9441e-07,\n",
      "        3.0933e-07, 6.3230e-08, 9.4455e-07, 9.3784e-09, 1.7746e-06, 1.7815e-05,\n",
      "        1.2661e-06, 1.3401e-09, 8.5477e-10, 2.3815e-07, 3.7757e-08, 1.6831e-07,\n",
      "        1.2360e-08, 1.6795e-07, 1.5823e-09, 1.2864e-10, 2.7161e-08, 2.7271e-07,\n",
      "        2.9025e-10, 2.6409e-09, 9.5163e-09, 7.4409e-10, 5.4729e-09, 1.6419e-07,\n",
      "        5.4872e-09, 1.3228e-09, 1.6326e-10, 4.7327e-09, 3.9094e-08, 3.8372e-10,\n",
      "        1.0791e-07, 5.7517e-06, 1.8012e-08, 1.6825e-07, 1.0469e-07, 1.9337e-09,\n",
      "        1.0635e-07, 8.1951e-09, 1.1388e-08, 3.9547e-08, 9.5611e-09, 9.0711e-09,\n",
      "        4.4969e-08, 1.8724e-08, 1.1158e-06, 3.1115e-09, 1.5040e-09, 2.7073e-08,\n",
      "        7.9635e-06, 1.3507e-07, 1.8715e-05, 1.0928e-08, 3.8771e-08, 3.7427e-08,\n",
      "        3.6956e-07, 4.6237e-09, 2.1943e-09, 1.2958e-06, 2.6733e-08, 4.4950e-07,\n",
      "        1.8273e-07, 2.6564e-08, 9.3490e-08, 5.8484e-08, 5.1352e-07, 2.8845e-09,\n",
      "        1.2448e-07, 1.8902e-08, 9.7367e-09, 4.1261e-08, 3.0912e-08, 3.0476e-08,\n",
      "        1.4176e-08, 9.5059e-08, 4.4200e-09, 3.8532e-07, 7.0807e-07, 6.3026e-07,\n",
      "        3.7791e-08, 7.4384e-07, 7.7573e-09, 3.3407e-07, 1.2581e-07, 2.0155e-07,\n",
      "        2.0791e-08, 1.1704e-06, 1.6405e-08, 1.8663e-09, 4.1203e-09, 1.3660e-10,\n",
      "        1.4929e-09, 7.2433e-06, 8.0825e-07, 2.1262e-08, 3.4973e-07, 4.7633e-08,\n",
      "        2.0302e-09, 7.1417e-09, 7.5131e-08, 8.6088e-08, 6.3421e-08, 6.2071e-06,\n",
      "        1.5950e-09, 1.8330e-08, 3.9443e-08, 5.7094e-07, 4.2902e-08, 5.6183e-08,\n",
      "        3.9001e-08, 1.3496e-07, 4.9531e-07, 6.9830e-08, 1.0207e-07, 1.6499e-08,\n",
      "        3.4227e-08, 2.9983e-08, 1.6111e-07, 4.3264e-08, 3.7930e-08, 9.2533e-08,\n",
      "        6.4846e-08, 9.6254e-09, 6.1943e-11, 1.3029e-08, 5.0824e-08, 1.4045e-07,\n",
      "        1.1046e-07, 2.3505e-08, 2.3858e-08, 2.8332e-08, 2.4030e-07, 1.6731e-08,\n",
      "        4.1422e-09, 4.8609e-08, 6.3068e-07, 1.5774e-07, 4.8318e-09, 2.3072e-08,\n",
      "        5.7036e-08, 1.1090e-08, 2.4691e-07, 5.3695e-08, 6.4622e-09, 2.6241e-07,\n",
      "        9.3138e-07, 3.9233e-08, 4.6514e-08, 8.7863e-08, 5.5287e-08, 9.9373e-09,\n",
      "        9.7113e-08, 1.0539e-08, 6.5516e-08, 9.3277e-09, 3.4699e-08, 1.8009e-08,\n",
      "        7.7791e-07, 6.1546e-07, 4.6248e-08, 1.0028e-04, 1.3867e-07, 1.9193e-07,\n",
      "        6.9529e-09, 2.3246e-07, 1.6314e-06, 5.9544e-07, 5.1491e-07, 8.7220e-08,\n",
      "        3.3878e-09, 6.2923e-08, 3.3410e-08, 3.8067e-09, 4.2576e-08, 1.6632e-08,\n",
      "        4.0667e-07, 1.8648e-07, 2.3111e-08, 1.4507e-09, 8.0487e-09, 2.7594e-08,\n",
      "        3.5990e-07, 3.4610e-07, 3.9495e-09, 2.0812e-08, 1.3588e-08, 4.4780e-08,\n",
      "        4.6278e-09, 4.1813e-08, 1.6137e-06, 1.0604e-06, 2.2817e-08, 9.7556e-09,\n",
      "        7.4241e-09, 2.4291e-08, 2.1894e-07, 1.2270e-08, 2.5550e-06, 5.1013e-08,\n",
      "        1.3499e-09, 2.7772e-06, 1.3457e-07, 5.7078e-08, 8.2226e-08, 3.8123e-08,\n",
      "        2.6737e-08, 2.1011e-08, 4.2797e-08, 8.3068e-08, 3.8077e-08, 7.0977e-08,\n",
      "        1.3940e-07, 3.8549e-08, 8.9000e-08, 1.1111e-08, 1.1053e-07, 2.4576e-07,\n",
      "        1.3453e-07, 1.7200e-08, 3.1522e-08, 6.1852e-09, 6.4482e-09, 2.0598e-07,\n",
      "        2.1546e-08, 1.0897e-08, 3.9377e-08, 2.4566e-08, 1.0281e-07, 4.3847e-08,\n",
      "        8.5840e-09, 1.9112e-07, 1.0660e-08, 5.8555e-08, 2.2080e-08, 8.6716e-07,\n",
      "        1.1521e-08, 2.4059e-09, 1.7191e-08, 1.5840e-08, 1.8739e-08, 1.2100e-08,\n",
      "        1.7463e-07, 5.9390e-08, 3.2760e-07, 6.2645e-07, 3.4605e-08, 5.7627e-09,\n",
      "        3.4936e-06, 2.2685e-07, 1.4248e-08, 6.7867e-09, 2.1954e-09, 2.7328e-08,\n",
      "        2.7596e-09, 7.5975e-08, 9.8365e-08, 5.7074e-08, 1.4934e-08, 8.6341e-07,\n",
      "        6.0597e-08, 3.6638e-08, 3.0802e-08, 1.4359e-08, 2.6120e-08, 8.1299e-08,\n",
      "        5.2546e-08, 4.3272e-07, 4.9774e-09, 1.1922e-08, 3.3662e-07, 1.9918e-07,\n",
      "        1.5832e-09, 2.8096e-09, 6.3174e-08, 1.7289e-08, 1.3523e-08, 9.8024e-07,\n",
      "        5.8045e-09, 4.2092e-08, 1.1740e-08, 1.7296e-08, 1.2620e-08, 1.2203e-07,\n",
      "        1.4919e-07, 7.4394e-08, 3.7016e-09, 1.4473e-08, 2.3468e-07, 1.4241e-07,\n",
      "        3.1445e-08, 8.0404e-09, 8.6687e-09, 2.6947e-09, 5.5770e-08, 1.0458e-06,\n",
      "        8.8762e-08, 1.1734e-07, 2.7616e-08, 1.9165e-09, 1.2841e-07, 9.8605e-09,\n",
      "        1.7343e-08, 4.7843e-08, 1.7879e-08, 1.4568e-07, 2.3564e-09, 6.6189e-07,\n",
      "        2.9993e-07, 4.3193e-08, 2.5565e-08, 9.1214e-08, 2.2855e-08, 5.6940e-08,\n",
      "        8.6991e-09, 9.1013e-08, 9.8955e-08, 1.9729e-07, 8.2889e-09, 2.4828e-09,\n",
      "        1.3043e-08, 1.4860e-08, 1.4877e-07, 2.0288e-07, 2.5091e-07, 1.7146e-08,\n",
      "        5.3207e-09, 1.1224e-08, 4.0328e-08, 1.9576e-08, 1.0180e-08, 9.7797e-09,\n",
      "        5.4150e-08, 2.5145e-09, 4.8143e-09, 5.3105e-08, 3.7715e-09, 5.3493e-08,\n",
      "        2.1777e-08, 1.0363e-08, 1.8225e-07, 7.4211e-09, 1.2473e-08, 1.8150e-08,\n",
      "        2.1283e-08, 3.5859e-08, 1.3745e-05, 6.0786e-07, 4.4988e-08, 1.1814e-07,\n",
      "        4.2213e-11, 7.4973e-08, 2.2472e-07, 1.7318e-09, 1.4965e-07, 3.3718e-07,\n",
      "        2.5087e-10, 4.4702e-07, 1.8973e-10, 9.2182e-09, 9.0549e-09, 1.3791e-08,\n",
      "        4.2057e-08, 1.9459e-09, 4.5519e-08, 9.8152e-09, 5.5372e-07, 2.5335e-09,\n",
      "        1.8347e-07, 2.7408e-09, 9.5239e-08, 3.6469e-09, 1.1085e-07, 1.1330e-07,\n",
      "        2.9018e-07, 1.4003e-07, 1.4363e-08, 7.8790e-08, 4.0710e-08, 1.4031e-07,\n",
      "        1.5985e-07, 1.1954e-08, 9.6139e-07, 1.0538e-08, 2.4998e-08, 1.5275e-07,\n",
      "        3.3862e-08, 7.7591e-10, 3.0463e-09, 1.3466e-08, 4.2432e-08, 1.2673e-08,\n",
      "        3.3347e-07, 1.4657e-07, 3.0276e-08, 1.3481e-08, 1.4529e-07, 6.4912e-09,\n",
      "        6.6585e-10, 7.3691e-08, 1.3037e-07, 3.4177e-08, 4.7387e-08, 9.7296e-10,\n",
      "        3.4026e-08, 4.3107e-09, 8.9948e-08, 5.2954e-08, 2.1631e-07, 4.4404e-09,\n",
      "        1.8378e-09, 8.1613e-07, 5.5040e-09, 3.5061e-08, 4.2519e-09, 3.7481e-09,\n",
      "        2.4569e-07, 4.6065e-08, 4.6054e-08, 2.4300e-08, 1.2335e-08, 3.1414e-07,\n",
      "        2.3152e-09, 2.7595e-08, 4.9086e-08, 2.5750e-10, 2.9980e-08, 7.1895e-09,\n",
      "        3.7784e-08, 2.9034e-05, 1.0017e-08, 8.0669e-06, 3.0960e-07, 7.3203e-07,\n",
      "        1.0972e-07, 4.1944e-08, 3.1141e-09, 1.7194e-07, 3.2047e-08, 1.1429e-08,\n",
      "        8.0434e-09, 2.4465e-07, 3.4590e-07, 3.8516e-08, 1.1029e-07, 2.3979e-09,\n",
      "        1.5972e-06, 5.0935e-07, 4.3861e-08, 1.3579e-08, 1.6353e-06, 3.0021e-07,\n",
      "        2.1483e-08, 4.6549e-08, 1.1004e-08, 2.1831e-07, 5.5895e-10, 3.1818e-08,\n",
      "        3.2685e-08, 1.3014e-07, 2.5495e-08, 2.2838e-08, 3.7540e-08, 8.6932e-10,\n",
      "        1.3617e-08, 7.7831e-09, 1.5825e-07, 1.2378e-08, 2.9572e-08, 2.2168e-07,\n",
      "        9.3634e-09, 7.1442e-09, 7.3184e-08, 2.4457e-08, 1.5735e-08, 4.4020e-07,\n",
      "        5.7364e-06, 2.3542e-08, 8.2774e-08, 1.6506e-07, 2.1516e-08, 4.9580e-09,\n",
      "        3.7262e-07, 1.4370e-09, 5.8933e-08, 1.2386e-07, 4.0795e-08, 5.4029e-09,\n",
      "        2.6807e-09, 1.6676e-08, 1.1539e-07, 1.8275e-09, 2.9556e-08, 1.2521e-08,\n",
      "        7.7629e-07, 9.0177e-09, 4.9839e-07, 7.1368e-09, 9.3623e-10, 1.1743e-06,\n",
      "        1.1373e-06, 5.5370e-09, 3.0786e-08, 9.4567e-08, 1.3534e-07, 4.9243e-08,\n",
      "        5.2240e-08, 2.8364e-08, 3.3756e-08, 1.6524e-08, 1.4239e-08, 5.6535e-08,\n",
      "        3.5089e-09, 1.4949e-08, 1.2453e-08, 3.5533e-09, 3.9996e-06, 5.0273e-08,\n",
      "        6.1288e-08, 1.5835e-08, 8.3973e-07, 3.2515e-08, 2.6837e-07, 6.4551e-08,\n",
      "        2.2283e-08, 3.5002e-09, 4.6446e-08, 4.6684e-08, 3.8329e-08, 9.0972e-08,\n",
      "        4.3308e-08, 3.0801e-08, 3.1479e-09, 1.1620e-06, 9.4722e-08, 8.1647e-08,\n",
      "        9.1011e-09, 2.8214e-08, 2.2042e-08, 1.6215e-08, 5.1803e-07, 2.6821e-07,\n",
      "        5.8272e-08, 3.7746e-09, 3.4633e-10, 2.3352e-07, 1.4355e-09, 1.0691e-07,\n",
      "        7.0053e-09, 4.9468e-07, 7.1506e-07, 7.3271e-08, 2.0922e-09, 3.8482e-07,\n",
      "        7.4606e-10, 4.2073e-08, 3.3389e-09, 1.1921e-09, 4.3048e-09, 4.9462e-08,\n",
      "        5.1777e-07, 2.5578e-07, 7.4129e-08, 2.6345e-07, 5.0156e-08, 7.6991e-08,\n",
      "        2.3649e-07, 4.8609e-07, 6.5899e-08, 2.5836e-08, 9.3998e-08, 3.7891e-07,\n",
      "        5.0865e-08, 2.2566e-08, 1.7754e-07, 8.4025e-07, 2.5829e-09, 4.0827e-07,\n",
      "        3.4247e-08, 5.7122e-09, 8.9887e-07, 3.9320e-08, 2.7683e-07, 8.5744e-09,\n",
      "        4.1923e-10, 5.4668e-09, 1.4337e-08, 6.6943e-08, 6.2054e-09, 7.2157e-10,\n",
      "        4.6644e-08, 2.0128e-09, 2.7711e-07, 1.1654e-07, 2.8993e-07, 4.7771e-08,\n",
      "        8.0316e-08, 9.3882e-09, 1.7333e-08, 7.5262e-07, 5.0836e-08, 3.2336e-07,\n",
      "        2.0915e-07, 4.2776e-08, 1.4485e-08, 1.9298e-10, 7.4986e-08, 3.6710e-09,\n",
      "        4.6523e-08, 1.0410e-07, 1.2363e-07, 3.0285e-06, 3.6126e-08, 1.0946e-07,\n",
      "        5.6365e-08, 4.1848e-08, 5.6930e-07, 1.2599e-08, 4.1056e-08, 1.3859e-06,\n",
      "        4.5604e-07, 8.7499e-08, 1.0598e-06, 6.4955e-08], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    batch_1t = batch_1t.to('cuda')\n",
    "    batch_2t = batch_2t.to('cuda')\n",
    "    batch_3t = batch_3t.to('cuda')\n",
    "    batch_4t = batch_4t.to('cuda')\n",
    "    batch_5t = batch_5t.to('cuda')\n",
    "    model.to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    output1 = model(batch_1t)\n",
    "    output2 = model(batch_2t)\n",
    "    output3 = model(batch_3t)\n",
    "    output4 = model(batch_4t)\n",
    "    output5 = model(batch_5t)\n",
    "# Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
    "print(output1[0])\n",
    "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
    "probabilities1 = torch.nn.functional.softmax(output1[0], dim=0)\n",
    "probabilities2 = torch.nn.functional.softmax(output2[0], dim=0)\n",
    "probabilities3 = torch.nn.functional.softmax(output3[0], dim=0)\n",
    "probabilities4 = torch.nn.functional.softmax(output4[0], dim=0)\n",
    "probabilities5 = torch.nn.functional.softmax(output5[0], dim=0)\n",
    "print(probabilities1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d2ae9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\nateisgreat98\\Google Drive\\Classes\\Machine Learning\\RT\\imagenet_classes.txt') as f:\n",
    "    labels = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c536029b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malamute, malemute, Alaskan malamute 0.7719805240631104\n",
      "Siberian husky 0.1307085156440735\n",
      "Eskimo dog, husky 0.09069979190826416\n",
      "collie 0.002474157838150859\n",
      "Border collie 0.0011028110748156905\n",
      "----------------------------------------------\n",
      "fire engine, fire truck 0.8715716004371643\n",
      "recreational vehicle, RV, R.V. 0.10063236951828003\n",
      "minibus 0.006818058434873819\n",
      "mobile home, manufactured home 0.0045454371720552444\n",
      "passenger car, coach, carriage 0.0042034052312374115\n",
      "----------------------------------------------\n",
      "palace 0.4927009344100952\n",
      "church, church building 0.13224266469478607\n",
      "monastery 0.08217103034257889\n",
      "castle 0.041442736983299255\n",
      "flagpole, flagstaff 0.03878539055585861\n",
      "----------------------------------------------\n",
      "indigo bunting, indigo finch, indigo bird, Passerina cyanea 0.7083508372306824\n",
      "macaw 0.17929737269878387\n",
      "jay 0.07180939614772797\n",
      "lorikeet 0.0055875820107758045\n",
      "African grey, African gray, Psittacus erithacus 0.004894796758890152\n",
      "----------------------------------------------\n",
      "racer, race car, racing car 0.604986310005188\n",
      "sports car, sport car 0.38857248425483704\n",
      "car wheel 0.003472000826150179\n",
      "go-kart 0.0013110637664794922\n",
      "convertible 0.0004969218280166388\n"
     ]
    }
   ],
   "source": [
    "top5_prob1, top5_catid1 = torch.topk(probabilities1, 5)\n",
    "top5_prob2, top5_catid2 = torch.topk(probabilities2, 5)\n",
    "top5_prob3, top5_catid3 = torch.topk(probabilities3, 5)\n",
    "top5_prob4, top5_catid4 = torch.topk(probabilities4, 5)\n",
    "top5_prob5, top5_catid5 = torch.topk(probabilities5, 5)\n",
    "for i in range(top5_prob1.size(0)):\n",
    "    print(labels[top5_catid1[i]], top5_prob1[i].item())\n",
    "print('----------------------------------------------')\n",
    "for i in range(top5_prob2.size(0)):\n",
    "    print(labels[top5_catid2[i]], top5_prob2[i].item())\n",
    "print('----------------------------------------------')\n",
    "for i in range(top5_prob3.size(0)):\n",
    "    print(labels[top5_catid3[i]], top5_prob3[i].item())\n",
    "print('----------------------------------------------')\n",
    "for i in range(top5_prob4.size(0)):\n",
    "    print(labels[top5_catid4[i]], top5_prob4[i].item())\n",
    "print('----------------------------------------------')\n",
    "for i in range(top5_prob5.size(0)):\n",
    "    print(labels[top5_catid5[i]], top5_prob5[i].item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bb4c64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: module ConvBNActivation is treated as a zero-op.\n",
      "Warning: module InvertedResidual is treated as a zero-op.\n",
      "Warning: module Dropout is treated as a zero-op.\n",
      "Warning: module MobileNetV2 is treated as a zero-op.\n",
      "MobileNetV2(\n",
      "  3.505 M, 100.000% Params, 0.32 GMac, 100.000% MACs, \n",
      "  (features): Sequential(\n",
      "    2.224 M, 63.451% Params, 0.319 GMac, 99.600% MACs, \n",
      "    (0): ConvBNActivation(\n",
      "      0.001 M, 0.026% Params, 0.012 GMac, 3.760% MACs, \n",
      "      (0): Conv2d(0.001 M, 0.025% Params, 0.011 GMac, 3.384% MACs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(0.0 M, 0.002% Params, 0.001 GMac, 0.251% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.125% MACs, inplace=True)\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      0.001 M, 0.026% Params, 0.012 GMac, 3.635% MACs, \n",
      "      (conv): Sequential(\n",
      "        0.001 M, 0.026% Params, 0.012 GMac, 3.635% MACs, \n",
      "        (0): ConvBNActivation(\n",
      "          0.0 M, 0.010% Params, 0.005 GMac, 1.504% MACs, \n",
      "          (0): Conv2d(0.0 M, 0.008% Params, 0.004 GMac, 1.128% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.002% Params, 0.001 GMac, 0.251% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.125% MACs, inplace=True)\n",
      "        )\n",
      "        (1): Conv2d(0.001 M, 0.015% Params, 0.006 GMac, 2.006% MACs, 32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(0.0 M, 0.001% Params, 0.0 GMac, 0.125% MACs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      0.005 M, 0.147% Params, 0.034 GMac, 10.576% MACs, \n",
      "      (conv): Sequential(\n",
      "        0.005 M, 0.147% Params, 0.034 GMac, 10.576% MACs, \n",
      "        (0): ConvBNActivation(\n",
      "          0.002 M, 0.049% Params, 0.023 GMac, 7.145% MACs, \n",
      "          (0): Conv2d(0.002 M, 0.044% Params, 0.019 GMac, 6.017% MACs, 16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.005% Params, 0.002 GMac, 0.752% MACs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.376% MACs, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNActivation(\n",
      "          0.001 M, 0.030% Params, 0.004 GMac, 1.128% MACs, \n",
      "          (0): Conv2d(0.001 M, 0.025% Params, 0.003 GMac, 0.846% MACs, 96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.005% Params, 0.001 GMac, 0.188% MACs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.094% MACs, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(0.002 M, 0.066% Params, 0.007 GMac, 2.256% MACs, 96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(0.0 M, 0.001% Params, 0.0 GMac, 0.047% MACs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      0.009 M, 0.252% Params, 0.029 GMac, 8.931% MACs, \n",
      "      (conv): Sequential(\n",
      "        0.009 M, 0.252% Params, 0.029 GMac, 8.931% MACs, \n",
      "        (0): ConvBNActivation(\n",
      "          0.004 M, 0.107% Params, 0.012 GMac, 3.807% MACs, \n",
      "          (0): Conv2d(0.003 M, 0.099% Params, 0.011 GMac, 3.384% MACs, 24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.008% Params, 0.001 GMac, 0.282% MACs, 144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.141% MACs, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNActivation(\n",
      "          0.002 M, 0.045% Params, 0.005 GMac, 1.692% MACs, \n",
      "          (0): Conv2d(0.001 M, 0.037% Params, 0.004 GMac, 1.269% MACs, 144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.008% Params, 0.001 GMac, 0.282% MACs, 144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.141% MACs, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(0.003 M, 0.099% Params, 0.011 GMac, 3.384% MACs, 144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(0.0 M, 0.001% Params, 0.0 GMac, 0.047% MACs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      0.01 M, 0.285% Params, 0.017 GMac, 5.374% MACs, \n",
      "      (conv): Sequential(\n",
      "        0.01 M, 0.285% Params, 0.017 GMac, 5.374% MACs, \n",
      "        (0): ConvBNActivation(\n",
      "          0.004 M, 0.107% Params, 0.012 GMac, 3.807% MACs, \n",
      "          (0): Conv2d(0.003 M, 0.099% Params, 0.011 GMac, 3.384% MACs, 24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.008% Params, 0.001 GMac, 0.282% MACs, 144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.141% MACs, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNActivation(\n",
      "          0.002 M, 0.045% Params, 0.001 GMac, 0.423% MACs, \n",
      "          (0): Conv2d(0.001 M, 0.037% Params, 0.001 GMac, 0.317% MACs, 144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.008% Params, 0.0 GMac, 0.071% MACs, 144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.035% MACs, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(0.005 M, 0.131% Params, 0.004 GMac, 1.128% MACs, 144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(0.0 M, 0.002% Params, 0.0 GMac, 0.016% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      0.015 M, 0.424% Params, 0.012 GMac, 3.729% MACs, \n",
      "      (conv): Sequential(\n",
      "        0.015 M, 0.424% Params, 0.012 GMac, 3.729% MACs, \n",
      "        (0): ConvBNActivation(\n",
      "          0.007 M, 0.186% Params, 0.005 GMac, 1.645% MACs, \n",
      "          (0): Conv2d(0.006 M, 0.175% Params, 0.005 GMac, 1.504% MACs, 32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.011% Params, 0.0 GMac, 0.094% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.047% MACs, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNActivation(\n",
      "          0.002 M, 0.060% Params, 0.002 GMac, 0.564% MACs, \n",
      "          (0): Conv2d(0.002 M, 0.049% Params, 0.001 GMac, 0.423% MACs, 192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.011% Params, 0.0 GMac, 0.094% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.047% MACs, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(0.006 M, 0.175% Params, 0.005 GMac, 1.504% MACs, 192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(0.0 M, 0.002% Params, 0.0 GMac, 0.016% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      0.015 M, 0.424% Params, 0.012 GMac, 3.729% MACs, \n",
      "      (conv): Sequential(\n",
      "        0.015 M, 0.424% Params, 0.012 GMac, 3.729% MACs, \n",
      "        (0): ConvBNActivation(\n",
      "          0.007 M, 0.186% Params, 0.005 GMac, 1.645% MACs, \n",
      "          (0): Conv2d(0.006 M, 0.175% Params, 0.005 GMac, 1.504% MACs, 32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.011% Params, 0.0 GMac, 0.094% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.047% MACs, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNActivation(\n",
      "          0.002 M, 0.060% Params, 0.002 GMac, 0.564% MACs, \n",
      "          (0): Conv2d(0.002 M, 0.049% Params, 0.001 GMac, 0.423% MACs, 192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.011% Params, 0.0 GMac, 0.094% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.047% MACs, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(0.006 M, 0.175% Params, 0.005 GMac, 1.504% MACs, 192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(0.0 M, 0.002% Params, 0.0 GMac, 0.016% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      0.021 M, 0.601% Params, 0.008 GMac, 2.546% MACs, \n",
      "      (conv): Sequential(\n",
      "        0.021 M, 0.601% Params, 0.008 GMac, 2.546% MACs, \n",
      "        (0): ConvBNActivation(\n",
      "          0.007 M, 0.186% Params, 0.005 GMac, 1.645% MACs, \n",
      "          (0): Conv2d(0.006 M, 0.175% Params, 0.005 GMac, 1.504% MACs, 32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.011% Params, 0.0 GMac, 0.094% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.047% MACs, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNActivation(\n",
      "          0.002 M, 0.060% Params, 0.0 GMac, 0.141% MACs, \n",
      "          (0): Conv2d(0.002 M, 0.049% Params, 0.0 GMac, 0.106% MACs, 192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.011% Params, 0.0 GMac, 0.024% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.012% MACs, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(0.012 M, 0.351% Params, 0.002 GMac, 0.752% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(0.0 M, 0.004% Params, 0.0 GMac, 0.008% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      0.054 M, 1.548% Params, 0.011 GMac, 3.369% MACs, \n",
      "      (conv): Sequential(\n",
      "        0.054 M, 1.548% Params, 0.011 GMac, 3.369% MACs, \n",
      "        (0): ConvBNActivation(\n",
      "          0.025 M, 0.723% Params, 0.005 GMac, 1.575% MACs, \n",
      "          (0): Conv2d(0.025 M, 0.701% Params, 0.005 GMac, 1.504% MACs, 64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.022% Params, 0.0 GMac, 0.047% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.024% MACs, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNActivation(\n",
      "          0.004 M, 0.121% Params, 0.001 GMac, 0.282% MACs, \n",
      "          (0): Conv2d(0.003 M, 0.099% Params, 0.001 GMac, 0.212% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.022% Params, 0.0 GMac, 0.047% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.024% MACs, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(0.025 M, 0.701% Params, 0.005 GMac, 1.504% MACs, 384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(0.0 M, 0.004% Params, 0.0 GMac, 0.008% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      0.054 M, 1.548% Params, 0.011 GMac, 3.369% MACs, \n",
      "      (conv): Sequential(\n",
      "        0.054 M, 1.548% Params, 0.011 GMac, 3.369% MACs, \n",
      "        (0): ConvBNActivation(\n",
      "          0.025 M, 0.723% Params, 0.005 GMac, 1.575% MACs, \n",
      "          (0): Conv2d(0.025 M, 0.701% Params, 0.005 GMac, 1.504% MACs, 64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.022% Params, 0.0 GMac, 0.047% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.024% MACs, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNActivation(\n",
      "          0.004 M, 0.121% Params, 0.001 GMac, 0.282% MACs, \n",
      "          (0): Conv2d(0.003 M, 0.099% Params, 0.001 GMac, 0.212% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.022% Params, 0.0 GMac, 0.047% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.024% MACs, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(0.025 M, 0.701% Params, 0.005 GMac, 1.504% MACs, 384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(0.0 M, 0.004% Params, 0.0 GMac, 0.008% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      0.054 M, 1.548% Params, 0.011 GMac, 3.369% MACs, \n",
      "      (conv): Sequential(\n",
      "        0.054 M, 1.548% Params, 0.011 GMac, 3.369% MACs, \n",
      "        (0): ConvBNActivation(\n",
      "          0.025 M, 0.723% Params, 0.005 GMac, 1.575% MACs, \n",
      "          (0): Conv2d(0.025 M, 0.701% Params, 0.005 GMac, 1.504% MACs, 64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.022% Params, 0.0 GMac, 0.047% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.024% MACs, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNActivation(\n",
      "          0.004 M, 0.121% Params, 0.001 GMac, 0.282% MACs, \n",
      "          (0): Conv2d(0.003 M, 0.099% Params, 0.001 GMac, 0.212% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.022% Params, 0.0 GMac, 0.047% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.024% MACs, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(0.025 M, 0.701% Params, 0.005 GMac, 1.504% MACs, 384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(0.0 M, 0.004% Params, 0.0 GMac, 0.008% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      0.067 M, 1.901% Params, 0.013 GMac, 4.125% MACs, \n",
      "      (conv): Sequential(\n",
      "        0.067 M, 1.901% Params, 0.013 GMac, 4.125% MACs, \n",
      "        (0): ConvBNActivation(\n",
      "          0.025 M, 0.723% Params, 0.005 GMac, 1.575% MACs, \n",
      "          (0): Conv2d(0.025 M, 0.701% Params, 0.005 GMac, 1.504% MACs, 64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.022% Params, 0.0 GMac, 0.047% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.024% MACs, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNActivation(\n",
      "          0.004 M, 0.121% Params, 0.001 GMac, 0.282% MACs, \n",
      "          (0): Conv2d(0.003 M, 0.099% Params, 0.001 GMac, 0.212% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.022% Params, 0.0 GMac, 0.047% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.024% MACs, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(0.037 M, 1.052% Params, 0.007 GMac, 2.256% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(0.0 M, 0.005% Params, 0.0 GMac, 0.012% MACs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): InvertedResidual(\n",
      "      0.118 M, 3.375% Params, 0.023 GMac, 7.309% MACs, \n",
      "      (conv): Sequential(\n",
      "        0.118 M, 3.375% Params, 0.023 GMac, 7.309% MACs, \n",
      "        (0): ConvBNActivation(\n",
      "          0.056 M, 1.611% Params, 0.011 GMac, 3.490% MACs, \n",
      "          (0): Conv2d(0.055 M, 1.578% Params, 0.011 GMac, 3.384% MACs, 96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.033% Params, 0.0 GMac, 0.071% MACs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.035% MACs, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNActivation(\n",
      "          0.006 M, 0.181% Params, 0.001 GMac, 0.423% MACs, \n",
      "          (0): Conv2d(0.005 M, 0.148% Params, 0.001 GMac, 0.317% MACs, 576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.033% Params, 0.0 GMac, 0.071% MACs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.035% MACs, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(0.055 M, 1.578% Params, 0.011 GMac, 3.384% MACs, 576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(0.0 M, 0.005% Params, 0.0 GMac, 0.012% MACs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): InvertedResidual(\n",
      "      0.118 M, 3.375% Params, 0.023 GMac, 7.309% MACs, \n",
      "      (conv): Sequential(\n",
      "        0.118 M, 3.375% Params, 0.023 GMac, 7.309% MACs, \n",
      "        (0): ConvBNActivation(\n",
      "          0.056 M, 1.611% Params, 0.011 GMac, 3.490% MACs, \n",
      "          (0): Conv2d(0.055 M, 1.578% Params, 0.011 GMac, 3.384% MACs, 96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.033% Params, 0.0 GMac, 0.071% MACs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.035% MACs, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNActivation(\n",
      "          0.006 M, 0.181% Params, 0.001 GMac, 0.423% MACs, \n",
      "          (0): Conv2d(0.005 M, 0.148% Params, 0.001 GMac, 0.317% MACs, 576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.033% Params, 0.0 GMac, 0.071% MACs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.035% MACs, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(0.055 M, 1.578% Params, 0.011 GMac, 3.384% MACs, 576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(0.0 M, 0.005% Params, 0.0 GMac, 0.012% MACs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): InvertedResidual(\n",
      "      0.155 M, 4.430% Params, 0.016 GMac, 5.011% MACs, \n",
      "      (conv): Sequential(\n",
      "        0.155 M, 4.430% Params, 0.016 GMac, 5.011% MACs, \n",
      "        (0): ConvBNActivation(\n",
      "          0.056 M, 1.611% Params, 0.011 GMac, 3.490% MACs, \n",
      "          (0): Conv2d(0.055 M, 1.578% Params, 0.011 GMac, 3.384% MACs, 96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.033% Params, 0.0 GMac, 0.071% MACs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.035% MACs, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNActivation(\n",
      "          0.006 M, 0.181% Params, 0.0 GMac, 0.106% MACs, \n",
      "          (0): Conv2d(0.005 M, 0.148% Params, 0.0 GMac, 0.079% MACs, 576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.033% Params, 0.0 GMac, 0.018% MACs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.009% MACs, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(0.092 M, 2.629% Params, 0.005 GMac, 1.410% MACs, 576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(0.0 M, 0.009% Params, 0.0 GMac, 0.005% MACs, 160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): InvertedResidual(\n",
      "      0.32 M, 9.130% Params, 0.016 GMac, 4.926% MACs, \n",
      "      (conv): Sequential(\n",
      "        0.32 M, 9.130% Params, 0.016 GMac, 4.926% MACs, \n",
      "        (0): ConvBNActivation(\n",
      "          0.156 M, 4.437% Params, 0.008 GMac, 2.394% MACs, \n",
      "          (0): Conv2d(0.154 M, 4.382% Params, 0.008 GMac, 2.350% MACs, 160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.002 M, 0.055% Params, 0.0 GMac, 0.029% MACs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.015% MACs, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNActivation(\n",
      "          0.011 M, 0.301% Params, 0.001 GMac, 0.176% MACs, \n",
      "          (0): Conv2d(0.009 M, 0.247% Params, 0.0 GMac, 0.132% MACs, 960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(0.002 M, 0.055% Params, 0.0 GMac, 0.029% MACs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.015% MACs, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(0.154 M, 4.382% Params, 0.008 GMac, 2.350% MACs, 960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(0.0 M, 0.009% Params, 0.0 GMac, 0.005% MACs, 160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (16): InvertedResidual(\n",
      "      0.32 M, 9.130% Params, 0.016 GMac, 4.926% MACs, \n",
      "      (conv): Sequential(\n",
      "        0.32 M, 9.130% Params, 0.016 GMac, 4.926% MACs, \n",
      "        (0): ConvBNActivation(\n",
      "          0.156 M, 4.437% Params, 0.008 GMac, 2.394% MACs, \n",
      "          (0): Conv2d(0.154 M, 4.382% Params, 0.008 GMac, 2.350% MACs, 160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.002 M, 0.055% Params, 0.0 GMac, 0.029% MACs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.015% MACs, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNActivation(\n",
      "          0.011 M, 0.301% Params, 0.001 GMac, 0.176% MACs, \n",
      "          (0): Conv2d(0.009 M, 0.247% Params, 0.0 GMac, 0.132% MACs, 960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(0.002 M, 0.055% Params, 0.0 GMac, 0.029% MACs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.015% MACs, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(0.154 M, 4.382% Params, 0.008 GMac, 2.350% MACs, 960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(0.0 M, 0.009% Params, 0.0 GMac, 0.005% MACs, 160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (17): InvertedResidual(\n",
      "      0.474 M, 13.522% Params, 0.023 GMac, 7.281% MACs, \n",
      "      (conv): Sequential(\n",
      "        0.474 M, 13.522% Params, 0.023 GMac, 7.281% MACs, \n",
      "        (0): ConvBNActivation(\n",
      "          0.156 M, 4.437% Params, 0.008 GMac, 2.394% MACs, \n",
      "          (0): Conv2d(0.154 M, 4.382% Params, 0.008 GMac, 2.350% MACs, 160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.002 M, 0.055% Params, 0.0 GMac, 0.029% MACs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.015% MACs, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNActivation(\n",
      "          0.011 M, 0.301% Params, 0.001 GMac, 0.176% MACs, \n",
      "          (0): Conv2d(0.009 M, 0.247% Params, 0.0 GMac, 0.132% MACs, 960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(0.002 M, 0.055% Params, 0.0 GMac, 0.029% MACs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.015% MACs, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(0.307 M, 8.765% Params, 0.015 GMac, 4.701% MACs, 960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(0.001 M, 0.018% Params, 0.0 GMac, 0.010% MACs, 320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (18): ConvBNActivation(\n",
      "      0.412 M, 11.760% Params, 0.02 GMac, 6.326% MACs, \n",
      "      (0): Conv2d(0.41 M, 11.687% Params, 0.02 GMac, 6.267% MACs, 320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(0.003 M, 0.073% Params, 0.0 GMac, 0.039% MACs, 1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.020% MACs, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    1.281 M, 36.549% Params, 0.001 GMac, 0.400% MACs, \n",
      "    (0): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.2, inplace=False)\n",
      "    (1): Linear(1.281 M, 36.549% Params, 0.001 GMac, 0.400% MACs, in_features=1280, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "Computational complexity:       0.32 GMac\n",
      "Number of parameters:           3.5 M   \n"
     ]
    }
   ],
   "source": [
    "from ptflops import get_model_complexity_info\n",
    "from torchvision import models\n",
    "with torch.cuda.device(0):\n",
    "  net = models.mobilenet_v2()\n",
    "  macs, params = get_model_complexity_info(net, (3, 224, 224), as_strings=True,\n",
    "                                           print_per_layer_stat=True, verbose=True)\n",
    "  print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "  print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b57c76f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
